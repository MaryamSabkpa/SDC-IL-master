{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def similarity(inputs_):\n",
    "    # Compute similarity mat of deep feature\n",
    "    # n = inputs_.size(0)\n",
    "    sim = torch.matmul(inputs_, inputs_.t())\n",
    "    return sim\n",
    "\n",
    "\n",
    "def GaussDistribution(data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mean_value = torch.mean(data).data[0]\n",
    "    diff = data - mean_value\n",
    "    std = torch.sqrt(torch.mean(torch.pow(diff, 2))).data[0]\n",
    "    return mean_value, std\n",
    "\n",
    "\n",
    "class MarginPositiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarginPositiveLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        n = inputs.size(0)\n",
    "        # Compute similarity matrix\n",
    "        sim_mat = similarity(inputs)\n",
    "        # print(sim_mat)\n",
    "        targets = targets.cuda()\n",
    "        # split the positive and negative pairs\n",
    "        eyes_ = Variable(torch.eye(n, n)).cuda()\n",
    "        # eyes_ = Variable(torch.eye(n, n))\n",
    "        pos_mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
    "        neg_mask = eyes_.eq(eyes_) - pos_mask\n",
    "        pos_mask = pos_mask - eyes_.eq(1)\n",
    "\n",
    "        pos_sim = torch.masked_select(sim_mat, pos_mask)\n",
    "        neg_sim = torch.masked_select(sim_mat, neg_mask)\n",
    "\n",
    "        num_instances = len(pos_sim)//n + 1\n",
    "        num_neg_instances = n - num_instances\n",
    "\n",
    "        pos_sim = pos_sim.resize(len(pos_sim)//(num_instances-1), num_instances-1)\n",
    "        neg_sim = neg_sim.resize(\n",
    "            len(neg_sim) // num_neg_instances, num_neg_instances)\n",
    "\n",
    "        #  clear way to compute the loss first\n",
    "        loss = list()\n",
    "        c = 0\n",
    "\n",
    "        # gauss is a numpy matrix to keep the gaussian mean and variance\n",
    "        # and intersection point value\n",
    "\n",
    "        gauss = np.zeros([n, 5])\n",
    "\n",
    "        for i, pos_pair in enumerate(pos_sim):\n",
    "            # print(i)\n",
    "            pos_pair = torch.sort(pos_pair)[0]\n",
    "            neg_pair = torch.sort(neg_sim[i])[0]\n",
    "\n",
    "            pos_mean, pos_std = GaussDistribution(pos_pair)\n",
    "            neg_mean, neg_std = GaussDistribution(neg_pair)\n",
    "\n",
    "            inter = (neg_std*pos_mean + pos_std*neg_mean)/(pos_std + neg_std)\n",
    "            inter = 0.8*inter + 0.1\n",
    "            gauss[i] = [pos_mean, neg_mean, pos_std, neg_std, inter]\n",
    "            neg_pair = torch.masked_select(neg_pair, neg_pair > pos_pair[0] - 0.05)\n",
    "            # pos_pair = pos_pair[1:]\n",
    "            if len(neg_pair) < 1:\n",
    "                c += 1\n",
    "                continue\n",
    "\n",
    "            neg_pair = torch.sort(neg_pair)[0]\n",
    "            # positive selection \n",
    "            pos_pair = torch.masked_select(pos_pair, pos_pair < neg_pair[-1] + 0.05)\n",
    "\t\n",
    "            if len(pos_pair) < 1:\n",
    "                c += 1\n",
    "                continue\n",
    "            \n",
    "            if i == 1 and np.random.randint(199) == 1:\n",
    "                print('neg_pair is ---------', neg_pair)\n",
    "                print('pos_pair is ---------', pos_pair.data)\n",
    "            pos_loss = torch.mean((inter - pos_pair))\n",
    "\n",
    "            neg_loss = 0.05*torch.mean(torch.log(1 + torch.exp(40*(neg_pair - inter ))))\n",
    "            loss.append(pos_loss + neg_loss)\n",
    "        print(gauss[1])\n",
    "        loss = torch.sum(torch.cat(loss))/n\n",
    "\n",
    "        prec = float(c)/n\n",
    "        neg_d = torch.mean(neg_sim).data[0]\n",
    "        pos_d = torch.mean(pos_sim).data[0]\n",
    "\n",
    "        return loss, prec, pos_d, neg_d\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_size = 32\n",
    "    input_dim = 3\n",
    "    output_dim = 2\n",
    "    num_class = 4\n",
    "    # margin = 0.5\n",
    "    x = Variable(torch.rand(data_size, input_dim), requires_grad=False)\n",
    "    # print(x)\n",
    "    w = Variable(torch.rand(input_dim, output_dim), requires_grad=True)\n",
    "    inputs = x.mm(w)\n",
    "    y_ = 8*list(range(num_class))\n",
    "    targets = Variable(torch.IntTensor(y_))\n",
    "\n",
    "    print(MarginPositiveLoss()(inputs, targets))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('Congratulations to you!')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
