{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class HistogramLoss(torch.nn.Module):\n",
    "    def __init__(self, num_steps, use_gpu=True):\n",
    "        super(HistogramLoss, self).__init__()\n",
    "        self.step = 2 / (num_steps - 1)\n",
    "        self.use_gpu = use_gpu\n",
    "        self.t = torch.range(-1, 1, self.step).view(-1, 1)\n",
    "        self.tsize = self.t.size()[0]\n",
    "        if self.use_gpu:\n",
    "            self.t = self.t.cuda()\n",
    "        \n",
    "    def forward(self, features, classes):\n",
    "        def histogram(inds, size):\n",
    "            s_repeat_ = s_repeat.clone()\n",
    "            indsa = (delta_repeat == (self.t - self.step)) & inds\n",
    "            indsb = (delta_repeat == self.t) & inds\n",
    "            s_repeat_[~(indsb|indsa)] = 0\n",
    "            s_repeat_[indsa] = (s_repeat_ - Variable(self.t) + self.step)[indsa] / self.step\n",
    "            s_repeat_[indsb] = (-s_repeat_ + Variable(self.t) + self.step)[indsb] / self.step\n",
    "            \n",
    "            return s_repeat_.sum(1) / size\n",
    "        \n",
    "        classes_size = classes.size()[0]\n",
    "        classes_eq = (classes.repeat(classes_size, 1)  == classes.view(-1, 1).repeat(1, classes_size)).data\n",
    "        dists = torch.mm(features, features.transpose(0, 1))\n",
    "        s_inds = torch.triu(torch.ones(dists.size()), 1).byte()\n",
    "        if self.use_gpu:\n",
    "            s_inds= s_inds.cuda()\n",
    "        pos_inds = classes_eq[s_inds].repeat(self.tsize, 1)\n",
    "        neg_inds = ~classes_eq[s_inds].repeat(self.tsize, 1)\n",
    "        pos_size = classes_eq[s_inds].sum()\n",
    "        neg_size = (~classes_eq[s_inds]).sum()\n",
    "        s = dists[s_inds].view(1, -1)\n",
    "        s_repeat = s.repeat(self.tsize, 1)\n",
    "        delta_repeat = (torch.floor((s_repeat.data + 1) / self.step) * self.step - 1).float()\n",
    "        \n",
    "        histogram_pos = histogram(pos_inds, pos_size)\n",
    "        histogram_neg = histogram(neg_inds, neg_size)\n",
    "        histogram_pos_repeat = histogram_pos.view(-1, 1).repeat(1, histogram_pos.size()[0])\n",
    "        histogram_pos_inds = torch.tril(torch.ones(histogram_pos_repeat.size()), -1).byte()\n",
    "        if self.use_gpu:\n",
    "            histogram_pos_inds = histogram_pos_inds.cuda()\n",
    "        histogram_pos_repeat[histogram_pos_inds] = 0\n",
    "        histogram_pos_cdf = histogram_pos_repeat.sum(0)\n",
    "        loss = torch.sum(histogram_neg * histogram_pos_cdf)\n",
    "        \n",
    "        return loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
