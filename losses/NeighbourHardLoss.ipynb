{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "class NeighbourHardLoss(nn.Module):\n",
    "    def __init__(self, margin=0.05):\n",
    "        super(NeighbourHardLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.ranking_loss = nn.MarginRankingLoss(margin=margin)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        n = inputs.size(0)\n",
    "        # Compute pairwise distance, replace by the official when merged\n",
    "        dist = torch.pow(inputs, 2).sum(dim=1, keepdim=True).expand(n, n)\n",
    "        dist = dist + dist.t()\n",
    "        dist.addmm_(1, -2, inputs, inputs.t())\n",
    "        dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "        # For each anchor, find the hardest positive and negative\n",
    "        mask = targets.expand(n, n).eq(targets.expand(n, n).t())\n",
    "        eye_ = Variable(torch.eye(n)).cuda()\n",
    "        eye_ = eye_.eq(1)\n",
    "        pos_mask = mask - eye_\n",
    "\n",
    "        dist_ap, dist_an = [], []\n",
    "        for i in range(n):\n",
    "            dist_ap.append(dist[i][pos_mask[i]].min())\n",
    "            dist_an.append(dist[i][mask[i] == 0].min())\n",
    "        dist_ap = torch.cat(dist_ap)\n",
    "        dist_an = torch.cat(dist_an)\n",
    "        # Compute ranking hinge loss\n",
    "        y = dist_an.data.new()\n",
    "        y.resize_as_(dist_an.data)\n",
    "        y.fill_(1)\n",
    "        y = Variable(y)\n",
    "        loss = self.ranking_loss(dist_an, dist_ap, y)\n",
    "        prec = (dist_an.data > dist_ap.data).sum() * 1. / y.size(0)\n",
    "        dist_ap = torch.mean(dist.masked_select(pos_mask)).data[0]\n",
    "        dist_an = torch.mean(dist.masked_select(mask==0)).data[0]\n",
    "        return loss, prec, dist_ap, dist_an\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_size = 32\n",
    "    input_dim = 3\n",
    "    output_dim = 2\n",
    "    num_class = 4\n",
    "    # margin = 0.5\n",
    "    x = Variable(torch.rand(data_size, input_dim), requires_grad=False)\n",
    "    w = Variable(torch.rand(input_dim, output_dim), requires_grad=True)\n",
    "    # print('training data is ', x)\n",
    "    # print('initial parameters are ', w)\n",
    "    inputs = x.mm(w)\n",
    "    # print('extracted feature is :', inputs)\n",
    "\n",
    "    # y_ = np.random.randint(num_class, size=data_size)\n",
    "    y_ = 8*list(range(num_class))\n",
    "    targets = Variable(torch.IntTensor(y_))\n",
    "\n",
    "    print(NeighbourHardLoss(margin=0.1)(inputs, targets))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('Congratulations to you!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
