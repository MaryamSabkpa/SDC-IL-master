{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from .KNNSoftmax import KNNSoftmax\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def random_slice(nums):\n",
    "    dim = sum(nums)\n",
    "    index_ = list(range(dim))\n",
    "    random.shuffle(index_)\n",
    "    index_list = [index_[nums[i]:(nums[i] + nums[i + 1])]\n",
    "                  for i in range(len(nums) - 1)]\n",
    "    return index_list\n",
    "\n",
    "\n",
    "class BranchKNNSoftmax(nn.Module):\n",
    "    def __init__(self, alpha=40, k=100, nums=[0, 128, 128, 128, 128]):\n",
    "        super(BranchKNNSoftmax, self).__init__()\n",
    "        self.Nums = nums\n",
    "        self.alpha = alpha\n",
    "        self.K = k\n",
    "        self.index_list = random_slice(self.Nums)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # index_list = random_slice(self.Nums)\n",
    "        inputs = [inputs[:, k_index]\n",
    "                  for k_index in self.index_list]\n",
    "        loss_list, prec_list, pos_d_list, neg_d_list = [], [], [], []\n",
    "\n",
    "        for input_ in inputs:\n",
    "            norm = input_.norm(dim=1, p=2, keepdim=True)\n",
    "            input_ = input_.div(norm.expand_as(input_))\n",
    "            loss, prec_, pos_d, neg_d = KNNSoftmax(alpha=self.alpha)(input_, targets)\n",
    "            loss_list.append(loss)\n",
    "            prec_list.append(prec_)\n",
    "            pos_d_list.append(pos_d)\n",
    "            neg_d_list.append(neg_d)\n",
    "\n",
    "        loss = torch.mean(torch.cat(loss_list))\n",
    "        acc = np.mean(prec_list)\n",
    "        pos_d = np.mean((pos_d_list))\n",
    "        neg_d = np.mean((neg_d_list))\n",
    "\n",
    "        return loss, acc, pos_d, neg_d\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_size = 32\n",
    "    input_dim = 3\n",
    "    output_dim = 2\n",
    "    num_class = 4\n",
    "    # margin = 0.5\n",
    "    x = Variable(torch.rand(data_size, input_dim), requires_grad=False)\n",
    "    w = Variable(torch.rand(input_dim, output_dim), requires_grad=True)\n",
    "    inputs = x.mm(w)\n",
    "    y_ = 8 * list(range(num_class))\n",
    "    targets = Variable(torch.IntTensor(y_))\n",
    "    # print(BranchKNNSoftmax()(inputs, targets))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('Congratulations to you!')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
